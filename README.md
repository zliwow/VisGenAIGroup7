# VisGenAIGroup7 â€” Transparent Prompt-to-Vis Pipeline Demo

A prototype system that transforms **natural language questions** into a fully **transparent 6-step visualization reasoning pipeline**, and finally into an interpretable **Vega-Lite chart**.

This project is built for **CS7295: Data Visualization & Generative AI** at Northeastern University.

Unlike typical â€œblack-boxâ€ Prompt-to-Vis tools, this system exposes and visualizes each reasoning step, allowing users to **edit intermediate results**, **rerun downstream steps**, and understand exactly how a chart is constructed.

---

## âœ¨ Features

### ğŸ” Transparent 6-Step Pipeline

The system decomposes user prompts into six interpretable reasoning steps:

1. **Column Selection**  
2. **Intent Classification**  
3. **Aggregation & Filtering**  
4. **Plot Type Recommendation**  
5. **Encoding Assignment**  
6. **Vega-Lite Spec Generation**

Each step produces:

- Human-readable reasoning  
- Structured JSON output  
- Editable fields  

---

### ğŸ¤– Choose Your LLM Provider

Users can dynamically choose the backend model in the **Streamlit sidebar**:

- **OpenAI API**  
- **Groq API**

Then select from the supported models (e.g., Llama 3.3 70B, Llama 3.1 8B, GPTâ€‘4.x / GPTâ€‘5).

---

### ğŸ“Š Automatic Vega-Lite Visualizations

The final pipeline output is transformed into a full **Vega-Lite specification** and rendered directly in Streamlit via Altair.

---

### ğŸ§© Modular Architecture (For Developers)

- **Frontend**: Streamlit  
- **Backend**: LangChain + LangGraph  
- **Data Models**: Pydantic schemas  
- **Charts**: Vega-Lite  

This structure keeps the codebase clean, modular, and AI-friendly for vibe coding.

---

## ğŸš€ Quick Start

### 1. Create virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. API Keys

You may use **OpenAI** or **Groq**.

You can provide API keys in one of two ways:

#### Option A â€” via Streamlit sidebar  
Paste your API key(s) into the sidebar input fields.

#### Option B â€” using `.streamlit/secrets.toml`

Copy the example file:

```bash
cp .streamlit/secrets.toml.example .streamlit/secrets.toml
```

And fill in:

```toml
OPENAI_API_KEY = "your-openai-key"
GROQ_API_KEY = "your-groq-key"
```

---

### 4. Run the app

```bash
streamlit run src/frontend/app.py
```

---

## ğŸ§­ Usage

1. Open the app in your browser.  
2. In the **sidebar**, choose:
   - API Provider (**OpenAI** / **Groq**)  
   - Model  
   - (Optional) API key  
3. Upload a CSV file or load a sample dataset.  
4. Enter a natural language question, such as:
   - â€œWhich movie genres earn the most?â€  
   - â€œShow me revenue over time.â€  
5. The system will:
   - Run all **6 transparent reasoning steps**  
   - Display structured reasoning  
   - Allow editing each step  
   - Render a Vega-Lite chart  
6. Modify any step and regenerate downstream steps as needed.

---

## ğŸ’¡ Example Queries

- â€œCreate a bar chart showing total sales by category.â€  
- â€œWhich genre has the highest worldwide gross?â€  
- â€œPlot rating vs budget as a scatter plot.â€  
- â€œShow average revenue per year.â€  

---

## ğŸ§± Project Structure

```text
VisGenAIGroup7/
â”œâ”€ README.md                # é¢å‘æ‰€æœ‰äººï¼šè¿™æ˜¯å•¥ã€æ€ä¹ˆè·‘ã€ä¸€ä¸ªå›¾è§£é‡Šæ¶æ„
â”œâ”€ AGENTS.md                # é¢å‘ Copilot/Codexï¼šå¤š Agent åˆ†å·¥è¯´æ˜ï¼ˆè§’è‰²å®šä¹‰ + é¡¹ç›®ç»“æ„æŒ‡å—ï¼‰
â”œâ”€ .github/
â”‚   â””â”€ copilot-instructions.md  # å…¨å±€ coding çº¦æŸå’Œä¸Šä¸‹æ–‡ï¼ˆå¼ºåˆ¶è¡Œä¸ºè§„èŒƒ + ä»£ç é£æ ¼è§„åˆ™ï¼‰
â”œâ”€ docs/
â”‚   â”œâ”€ 01_project_overview.md   # é—®é¢˜ã€ç›®æ ‡ã€æœ¯è¯­
â”‚   â”œâ”€ 02_requirements.md       # é¡¹ç›®éœ€æ±‚ / èŒƒå›´ / éç›®æ ‡
â”‚   â”œâ”€ 03_architecture.md       # æŠ€æœ¯æ¶æ„ & æ¨¡å—åˆ’åˆ†
â”‚   â”œâ”€ 04_pipeline_design.md    # 6 æ­¥ Prompt-to-Vis pipeline æ˜ç»†
â”‚   â”œâ”€ 05_ui_design.md          # UI mockups & äº¤äº’è¯´æ˜ï¼ˆå›åº” Enrico çš„ commentï¼‰
â”‚   â””â”€ 06_prompts.md            # æ¯ä¸€æ­¥çš„ LLM prompt æ¨¡æ¿
â”œâ”€ src/
â”‚   â”œâ”€ frontend/
â”‚   â”‚   â”œâ”€ app.py               # Streamlit å…¥å£
â”‚   â”‚   â””â”€ components/          # TableView / ChartView / StepsPanel ç­‰
â”‚   â”œâ”€ backend/
â”‚   â”‚   â”œâ”€ pipeline/
â”‚   â”‚   â”‚   â”œâ”€ steps.py         # 6 ä¸ªæ­¥éª¤çš„ schema & å¸¸é‡
â”‚   â”‚   â”‚   â”œâ”€ workflow.py      # ç”¨ LangChain/LangGraph ä¸²è”çš„ pipeline
â”‚   â”‚   â”œâ”€ llm/
â”‚   â”‚   â”‚   â”œâ”€ base_client.py    # å®šä¹‰ç»Ÿä¸€æ¥å£ï¼ˆæŠ½è±¡ç±»ï¼‰
â”‚   â”‚   â”‚   â”œâ”€ prompt_loader.py  # ä» docs åŠ è½½ prompt
â”‚   â”‚   â”‚   â”œâ”€ openai_client.py  # è°ƒç”¨ GPT-5 çš„å°è£…
â”‚   â”‚   â”‚   â””â”€ groq_client.py    # è°ƒç”¨ Groq API çš„å°è£…
â”‚   â”‚   â””â”€ vega/
â”‚   â”‚       â””â”€ spec_builder.py  # æŠŠ 6 æ­¥ç»“æœæ‹¼æˆ Vega-Lite spec
â”‚   â””â”€ shared/
â”‚       â””â”€ schemas.py           # Pydantic æ•°æ®æ¨¡å‹ï¼šStepResult, PipelineState ç­‰
â”œâ”€ venv                         # è™šæ‹Ÿç¯å¢ƒ
â”œâ”€ requirements.txt             # Python ä¾èµ–
â”œâ”€ .streamlit/
â”‚   â””â”€ secrets.toml.example     # API key ç¤ºä¾‹
â”œâ”€ .gitignore
â””â”€ tests/
    â””â”€ test_pipeline.py         # å¯¹ pipeline çš„åŸºç¡€å•æµ‹

```

---

## âš ï¸ Current Limitations

- Only single-table datasets  
- No automatic data cleaning  
- Limited chart types  
- Not optimized for large datasets  
- LLM output may require manual correction  

---

## ğŸ™ Acknowledgements

This project builds on concepts from ChartGPT, VisRAG, Transparent Prompt-to-Vis pipelines, and other academic works from CS7295.
