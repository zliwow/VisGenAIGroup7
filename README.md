# VisGenAIGroup7 â€” Transparent Prompt-to-Vis Pipeline Demo

A prototype system that transforms **natural language questions** into a fully **transparent 6-step visualization reasoning pipeline**, and finally into an interpretable **Vega-Lite chart**.

This project is built for **CS7295: Data Visualization & Generative AI** at Northeastern University.

Unlike typical â€œblack-boxâ€ Prompt-to-Vis tools, this system exposes and visualizes each reasoning step, allowing users to **edit intermediate results**, **rerun downstream steps**, and understand exactly how a chart is constructed.

---

## âœ¨ Features

### ğŸ” Transparent 6-Step Pipeline

The system decomposes user prompts into six interpretable reasoning steps:

1. **Column Selection**  
2. **Intent Classification**  
3. **Aggregation & Filtering**  
4. **Plot Type Recommendation**  
5. **Encoding Assignment**  
6. **Vega-Lite Spec Generation**

Each step produces:

- Human-readable reasoning  
- Structured JSON output  
- Editable fields  

---

### ğŸ¤– Choose Your LLM Provider

Users can dynamically choose the backend model in the **Streamlit sidebar**:

- **OpenAI API**  
- **Groq API**

Then select from the supported models (e.g., Llama 3.3 70B, Llama 3.1 8B, GPTâ€‘4.x / GPTâ€‘5).

---

### ğŸ“Š Automatic Vega-Lite Visualizations

The final pipeline output is transformed into a full **Vega-Lite specification** and rendered directly in Streamlit via Altair.

---

### ğŸ§© Modular Architecture (For Developers)

- **Frontend**: Streamlit  
- **Backend**: LangChain + LangGraph  
- **Data Models**: Pydantic schemas  
- **Charts**: Vega-Lite  

This structure keeps the codebase clean, modular, and AI-friendly for vibe coding.

---

## ğŸš€ Quick Start

### 1. Create virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. API Keys

You may use **OpenAI** or **Groq**.

You can provide API keys in one of two ways:

#### Option A â€” via Streamlit sidebar  
Paste your API key(s) into the sidebar input fields.

#### Option B â€” using `.streamlit/secrets.toml`

Copy the example file:

```bash
cp .streamlit/secrets.toml.example .streamlit/secrets.toml
```

And fill in:

```toml
OPENAI_API_KEY = "your-openai-key"
GROQ_API_KEY = "your-groq-key"
```

---

### 4. Run the app

```bash
streamlit run src/frontend/app.py
```

---

## ğŸ§­ Usage

1. Open the app in your browser.  
2. In the **sidebar**, choose:
   - API Provider (**OpenAI** / **Groq**)  
   - Model  
   - (Optional) API key  
3. Upload a CSV file or load a sample dataset.  
4. Enter a natural language question, such as:
   - â€œWhich movie genres earn the most?â€  
   - â€œShow me revenue over time.â€  
5. The system will:
   - Run all **6 transparent reasoning steps**  
   - Display structured reasoning  
   - Allow editing each step  
   - Render a Vega-Lite chart  
6. Modify any step and regenerate downstream steps as needed.

---

## ğŸ’¡ Example Queries

- â€œCreate a bar chart showing total sales by category.â€  
- â€œWhich genre has the highest worldwide gross?â€  
- â€œPlot rating vs budget as a scatter plot.â€  
- â€œShow average revenue per year.â€  

---

## ğŸ§± Project Structure

```text
VisGenAIGroup7/
â”œâ”€ README.md                # Facing all audience
â”œâ”€ AGENTS.md                # Facing Copilot/Codex
â”œâ”€ .github/
â”‚   â””â”€ copilot-instructions.md  # Overall coding structure and context
â”œâ”€ docs/
â”‚   â”œâ”€ 01_project_overview.md   # Question, objective
â”‚   â”œâ”€ 02_requirements.md       # Project requirement
â”‚   â”œâ”€ 03_architecture.md       # Technical structure
â”‚   â”œâ”€ 04_pipeline_design.md    # 6 step Prompt-to-Vis pipeline
â”‚   â”œâ”€ 05_ui_design.md          # UI mockups & UI explanation
â”‚   â””â”€ 06_prompts.md            # Step to step LLM prompt sample
â”œâ”€ src/
â”‚   â”œâ”€ frontend/
â”‚   â”‚   â”œâ”€ app.py               # Streamlit access
â”‚   â”‚   â””â”€ components/          # TableView / ChartView / StepsPanel 
â”‚   â”œâ”€ backend/
â”‚   â”‚   â”œâ”€ pipeline/
â”‚   â”‚   â”‚   â”œâ”€ steps.py         # 6 step scheme
â”‚   â”‚   â”‚   â”œâ”€ workflow.py      # LangChain/LangGraph pipeline
â”‚   â”‚   â”œâ”€ llm/
â”‚   â”‚   â”‚   â”œâ”€ base_client.py    # define and standardize
â”‚   â”‚   â”‚   â”œâ”€ prompt_loader.py  # load prompt from doc
â”‚   â”‚   â”‚   â”œâ”€ openai_client.py  # GPT-5
â”‚   â”‚   â”‚   â””â”€ groq_client.py    # Groq API
â”‚   â”‚   â””â”€ vega/
â”‚   â”‚       â””â”€ spec_builder.py  # æŠŠ 6 æ­¥ç»“æœæ‹¼æˆ Vega-Lite spec
â”‚   â””â”€ shared/
â”‚       â””â”€ schemas.py           # Pydantic data modalï¼šStepResult, PipelineState ç­‰
â”œâ”€ venv                         # virture environment
â”œâ”€ requirements.txt             # Python reliance
â”œâ”€ .streamlit/
â”‚   â””â”€ secrets.toml.example     # API key demo
â”œâ”€ .gitignore
â””â”€ tests/
    â””â”€ test_pipeline.py         # basic testing of pipelines

```

---

## âš ï¸ Current Limitations

- Only single-table datasets  
- No automatic data cleaning  
- Limited chart types  
- Not optimized for large datasets  
- LLM output may require manual correction  

---

## ğŸ™ Acknowledgements

This project builds on concepts from ChartGPT, VisRAG, Transparent Prompt-to-Vis pipelines, and other academic works from CS7295.
